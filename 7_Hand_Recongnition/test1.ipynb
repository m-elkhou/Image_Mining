{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "# from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import joblib\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = 'D:/WISD/S3/Image_Mining/Atelier_7_HandRecongnition/'\n",
    "data_train_path = home + 'training/training/'\n",
    "data_GTtrain_path = home + 'training/GTtraining/'\n",
    "model_path = home + \"model_seg1.sav\""
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h1>Loading images and mask</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "0%|          | 0/90 [00:00<?, ?it/s]# Loading : [ START ]\n100%|██████████| 90/90 [00:04<00:00, 18.17it/s]\n# Loading : [ DONE ]\n"
    }
   ],
   "source": [
    "print('# Loading : [ START ]')\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "all_img_path = np.array(glob(data_train_path+\"*.*\"))\n",
    "all_mask_paths = np.array(glob(data_GTtrain_path+\"*.*\"))\n",
    "\n",
    "ss = ShuffleSplit(n_splits=1, test_size=0.1, random_state=42)\n",
    "for _, index in ss.split(all_img_path):\n",
    "    paths = zip( all_img_path[index], all_mask_paths[index])\n",
    "\n",
    "pbar = tqdm(total=len(all_img_path[index]))\n",
    "for img_path, mask_path in paths : \n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    img = img[3:198,3:198,:]\n",
    "\n",
    "    imgYCC = cv2.cvtColor(img, cv2.COLOR_BGR2YCR_CB)\n",
    "    imgYCC = imgYCC.reshape((-1, 3))\n",
    "\n",
    "    mask = cv2.imread(mask_path,0)\n",
    "    _, mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "    mask = mask.flatten()\n",
    "\n",
    "    for pixel in imgYCC:\n",
    "        features.append(np.array(pixel))\n",
    "    labels.extend(mask)\n",
    "\n",
    "    pbar.update(1)\n",
    "pbar.close()\n",
    "\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "np.save(home + 'features_seg.npy', features, allow_pickle=True)\n",
    "np.save(home + 'labels_seg.npy', labels, allow_pickle=True)\n",
    "print('# Loading : [ DONE ]')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h1>Predicting</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "# Predicting : [ START ]\n# Predicting : [ DONE ]\n# Time left  0:10:52.091643\n"
    }
   ],
   "source": [
    "print('# Predicting : [ START ]')\n",
    "date = datetime.today()\n",
    "features =np.load(home + 'features_seg.npy', allow_pickle=True)\n",
    "labels = np.load(home + 'labels_seg.npy', allow_pickle=True)\n",
    "\n",
    "# model = svm.SVC(gamma=0.01, C=1, kernel='rbf').fit(features, labeles)\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors = 10).fit(features, labels)\n",
    "\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# model=RandomForestRegressor(verbose=2,n_estimators=100)\n",
    "# model.fit(features, labels)\n",
    "joblib.dump(model, model_path)\n",
    "print('# Predicting : [ DONE ]')\n",
    "print('# Time left ', datetime.today() - date)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h1>Segmentation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 35721 into shape (195,195)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-da0aff309fa8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgYCC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m195\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m195\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Y = np.multiply(imgYCC[:,:,0], mask)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 35721 into shape (195,195)"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(home+'test/A2.jpg')\n",
    "\n",
    "img = img[3:198,3:198,:]\n",
    "imgYCC = cv2.cvtColor(img, cv2.COLOR_BGR2YCR_CB)\n",
    "imgYCC = imgYCC.reshape((-1, 3))\n",
    "\n",
    "# model = joblib.load(model_path)\n",
    "model = joblib.load(\"model_seg0.sav\")\n",
    "\n",
    "mask = model.predict(imgYCC)\n",
    "mask = np.array(mask).reshape((195,195))\n",
    "\n",
    "# Y = np.multiply(imgYCC[:,:,0], mask)\n",
    "# Cb = np.multiply(imgYCC[:,:,1], mask)\n",
    "# Cr = np.multiply(imgYCC[:,:,2], mask)\n",
    "# skin = np.dstack((Y,Cb,Cr)).astype(np.uint8)\n",
    "\n",
    "# apply a series of erosions and dilations to the mask using an elliptical kernel\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "mask = cv2.erode(mask, kernel, iterations = 2)\n",
    "mask = cv2.dilate(mask, kernel, iterations = 2)\n",
    "# blur the mask to help remove noise, then apply the mask to the frame\n",
    "mask = cv2.GaussianBlur(mask, (3, 3), 0)\n",
    "\n",
    "# _, mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnt = max(contours, key=cv2.contourArea)\n",
    "# Finding the convex hull of largest contour \n",
    "# hull = cv2.convexHull(cnt,returnPoints=True)    \n",
    "# cv2.drawContours(frameD,[hull],0,(0, 0, 255),2) # 5dar :  (0,255,0)\n",
    "x, y, width, height = cv2.boundingRect(cnt)   \n",
    "\n",
    "mask = cv2.merge((mask, mask, mask))\n",
    "\n",
    "skin = cv2.bitwise_and(img, mask)\n",
    "\n",
    "# skin = cv2.rectangle(skin, (x, y), (x + width, y + height), (0,255,0), 2) \n",
    "new_img = skin[y:(y + height),x:(x + width)]\n",
    "\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.xticks([]),plt.yticks([])\n",
    "plt.title('Image Originale')\n",
    "plt.imshow(img)\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.xticks([]),plt.yticks([])\n",
    "plt.title('mask')\n",
    "plt.imshow(mask)\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.xticks([]),plt.yticks([])\n",
    "plt.title('skin')\n",
    "plt.imshow(skin)\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.xticks([]),plt.yticks([])\n",
    "plt.title('new skin')\n",
    "plt.imshow(new_img)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15, 7]\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (195,195) (38025,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-675c91f846a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mCb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimgYCC\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mCr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimgYCC\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mCb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mCr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (195,195) (38025,) "
     ]
    }
   ],
   "source": [
    "Y = imgYCC[:,:,0]\n",
    "Cb = imgYCC[:,:,1]\n",
    "Cr = imgYCC[:,:,2]\n",
    "Y = np.multiply(Y, mask)\n",
    "Cb = np.multiply(Cb, mask)\n",
    "Cr = np.multiply(Cr, mask)\n",
    "Y , Cb, Cr = Y.flatten(), Cb.flatten(), Cr.flatten()\n",
    "print(Y.shape, Y)\n",
    "\n",
    "liste2 = []\n",
    "for i in range(len(Y)):\n",
    "    if Y[i] == 0 and Cb[i] == 0 and Cr[i] == 0:\n",
    "        pass\n",
    "    else:\n",
    "         liste2.append((Y[i], Cb[i], Cr[i]))\n",
    "featurs = [np.min(liste2[0]), np.max(liste2[0]), np.min(liste2[1]), np.max(liste2[1]), np.min(liste2[2]), np.max(liste2[2])]\n",
    "featurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h1>\n",
    "╔╦╗╔═╗╦ ╦╔═╗╔╦╗╔╦╗╔═╗╔╦╗   ╔═╗╦  ╦╔═╦ ╦╔═╗╦ ╦</br>\n",
    "║║║║ ║╠═╣╠═╣║║║║║║║╣  ║║   ║╣ ║  ╠╩╗╠═╣║ ║║ ║</br>\n",
    "╩ ╩╚═╝╩ ╩╩ ╩╩ ╩╩ ╩╚═╝═╩╝   ╚═╝╩═╝╩ ╩╩ ╩╚═╝╚═╝</br>\n",
    "</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}